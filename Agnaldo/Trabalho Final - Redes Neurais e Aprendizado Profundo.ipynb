{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Especialização em Inteligência Artificial – IFMG\n",
    "# Trabalho da disciplina de Redes Neurais e Aprendizado Profundo\n",
    "**Alunos**: \n",
    "- Alexandre Fortes Santana  \n",
    "- Bruno da Cunha Ferreira  \n",
    "- Thiago Duarte de Souza  \n",
    "- Cleverson José Murta Galdino  \n",
    "\n",
    "**Professor**: Agnaldo José da Rocha Reis - UFOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. O que é inteligência para você?\n",
    "\n",
    "Para mim, inteligência poderia ser definida pelos tópicos a seguir:\n",
    "- Inteligência se manifesta em diferentes graus e tipos;\n",
    "- Inteligência se desenvolve em um indivíduo, a princípio, biológico;\n",
    "- O indivíduo detentor de inteligência em questão precisa ter a capacidade de memorizar informações em alguma escala;\n",
    "- O indivíduo detentor de inteligência utiliza as informações a que tem acesso para interpretar o mundo a sua volta e a si mesmo;\n",
    "- O indivíduo detentor de inteligência é capaz de decisões, agir e criar novos artefatos (imaginários ou físicos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Em sua opinião, o que aconteceria se alguém descobrisse como implementar uma IA mais abrangente (e.g., AGI) em um robô?\n",
    "A descoberta de uma Inteligência Artificial Geral seria um marco histórico para a humanidade. Experimentaríamos um período de frenesi nas redes sociais, nos noticiários e nas rodas de conversa. Muitos dilemas seriam discutidos, abordando temas como mercado de trabalho, impacto social, segurança, regulação, ética e questões militares. Os primeiros robôs focariam em demonstrar o potencial de suas aplicações e em realizar apresentações que alimentassem o frenesi público. Após um período marcado por medo, especulações e empolgação, veríamos as primeiras aplicações práticas direcionadas a problemas reais. Os primeiros robôs comerciais seriam mais simples, devido ao elevado custo de produção, e não necessariamente seriam humanoides. Não, não acredito que as máquinas se revoltariam, levando a um apocalipse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Análise de um processo de destilação fracionada de petróleo\n",
    "A partir da análise de um processo de destilação fracionada de petróleo observou-se que determinado óleo poderia ser classificado em duas classes de pureza {C1 e C2}, mediante a medição de três grandezas {x1, x2 e x3} que representam algumas das propriedades físico-químicas do óleo. Para tanto, pretende-se utilizar um perceptron para executar a classificação automática dessas duas classes. Assim, baseadas nas informações coletadas do processo, formou-se o conjunto de treinamento em anexo (vou te passar a estrutura de dados nas próximas mensagens), tomando por convenção o valor –1 para óleo pertencente à classe C1 e o valor +1 para óleo pertencente à classe C2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Execute dois treinamentos para a rede perceptron, inicializando-se o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergiu na época 410\n",
      "[0.52722288 0.49369926 0.19142561 0.03145206]\n",
      "[30.92722288 15.64027926 24.84662561 -7.37272794]\n",
      "410\n",
      "Convergiu na época 432\n",
      "[0.13379696 0.11727471 0.46864307 0.59758338]\n",
      "[31.53379696 15.86509471 25.27912307 -7.48259662]\n",
      "432\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Vetor de Pesos Inicial</th>\n",
       "      <th>Vetor de Pesos Final</th>\n",
       "      <th>Número de Épocas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.527223</td>\n",
       "      <td>30.927223</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.493699</td>\n",
       "      <td>15.640279</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.191426</td>\n",
       "      <td>24.846626</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.031452</td>\n",
       "      <td>-7.372728</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.133797</td>\n",
       "      <td>31.533797</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.117275</td>\n",
       "      <td>15.865095</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.468643</td>\n",
       "      <td>25.279123</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.597583</td>\n",
       "      <td>-7.482597</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Treinamento  Vetor de Pesos Inicial  Vetor de Pesos Final Número de Épocas\n",
       "0          T1                0.527223             30.927223              410\n",
       "1          T1                0.493699             15.640279              410\n",
       "2          T1                0.191426             24.846626              410\n",
       "3          T1                0.031452             -7.372728              410\n",
       "4          T2                0.133797             31.533797              432\n",
       "5          T2                0.117275             15.865095              432\n",
       "6          T2                0.468643             25.279123              432\n",
       "7          T2                0.597583             -7.482597              432"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = np.loadtxt('tab_treinamento1.dat')\n",
    "training_data = data[:, :3]\n",
    "labels = data[:, 3]\n",
    "\n",
    "# Bias: Adicionando uma coluna de uns ao conjunto de dados de treinamento\n",
    "training_data = np.c_[np.ones(training_data.shape[0]), training_data]\n",
    "\n",
    "epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Inicialização de pesos\n",
    "def initialize_weights(dim):\n",
    "    return np.random.rand(dim)\n",
    "\n",
    "# Treinamento do Perceptron\n",
    "def train_perceptron(training_data, labels, learning_rate, epochs):\n",
    "    # Inicialização de pesos\n",
    "    weights = initialize_weights(training_data.shape[1])\n",
    "    initial_weights = np.copy(weights)\n",
    "    no_errors = 0\n",
    "    final_epoch = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(training_data)):\n",
    "            x = training_data[i]\n",
    "            y = labels[i]\n",
    "            \n",
    "            # Cálculo do output e função de ativação\n",
    "            output = np.dot(weights, x)\n",
    "            prediction = 1 if output > 0 else -1\n",
    "\n",
    "            # Atualização de pesos\n",
    "            if prediction != y:\n",
    "                weights += learning_rate * (y - prediction) * x\n",
    "                no_errors += 1\n",
    "\n",
    "        if no_errors == 0:\n",
    "            final_epoch = epoch+1\n",
    "            print(f\"Convergiu na época {final_epoch}\")\n",
    "            break\n",
    "        no_errors = 0 # reseta contador de erros\n",
    "                \n",
    "    return initial_weights, weights, final_epoch\n",
    "\n",
    "# DataFrame para armazenar os resultados\n",
    "results_df = pd.DataFrame(columns=[\"Treinamento\", \"Vetor de Pesos Inicial\", \"Vetor de Pesos Final\", \"Número de Épocas\"])\n",
    "\n",
    "# Executando Dois Treinamentos\n",
    "for i in range(2):\n",
    "    initial_weights, final_weights, final_epoch = train_perceptron(training_data, labels, learning_rate, epochs)  \n",
    "    \n",
    "    print(initial_weights)\n",
    "    print(final_weights)\n",
    "    print(final_epoch)\n",
    "\n",
    "    new_row_df = pd.DataFrame({\n",
    "        \"Treinamento\": f\"T{i+1}\",\n",
    "        \"Vetor de Pesos Inicial\": initial_weights,\n",
    "        \"Vetor de Pesos Final\": final_weights,\n",
    "        \"Número de Épocas\": final_epoch\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row_df], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = results_df.groupby(\"Treinamento\")[\"Vetor de Pesos Final\"].apply(list).reset_index()\n",
    "\n",
    "weights_T1 = np.array(grouped[grouped[\"Treinamento\"] == \"T1\"][\"Vetor de Pesos Final\"].iloc[0])\n",
    "weights_T2 = np.array(grouped[grouped[\"Treinamento\"] == \"T2\"][\"Vetor de Pesos Final\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Após o treinamento do perceptron, aplique-o na classificação automática de novas amostras de óleo (ver arquivo tab_teste1.dat), indicando-se na tabela seguinte os resultados das saídas (Classes) referentes aos dois processos de treinamento realizados no item a.**\n",
    "\n",
    "Para classificar novas amostras usando os pesos finais obtidos após o treinamento vamos criar uma função chamada classify_samples que receberá as novas amostras e os pesos finais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificações usando o treinamento T1: [-1.  1.  1.  1.  1.  1. -1.  1. -1. -1.]\n",
      "Classificações usando o treinamento T2: [-1.  1.  1.  1.  1.  1. -1.  1. -1. -1.]\n",
      "  Amostra      x1      x2      x3  y (T1)  y (T2)\n",
      "0      A1 -0.3565  0.0620  5.9891    -1.0    -1.0\n",
      "1      A2 -0.7842  1.1267  5.5912     1.0     1.0\n",
      "2      A3  0.3012  0.5611  5.8234     1.0     1.0\n",
      "3      A4  0.7757  1.0648  8.0677     1.0     1.0\n",
      "4      A5  0.1570  0.8028  6.3040     1.0     1.0\n",
      "5      A6 -0.7014  1.0316  3.6005     1.0     1.0\n",
      "6      A7  0.3748  0.1536  6.1537    -1.0    -1.0\n",
      "7      A8 -0.6920  0.9404  4.4058     1.0     1.0\n",
      "8      A9 -1.3970  0.7141  4.9263    -1.0    -1.0\n",
      "9     A10 -1.8842 -0.2805  1.2548    -1.0    -1.0\n"
     ]
    }
   ],
   "source": [
    "new_samples = np.loadtxt('tab_teste1.dat')\n",
    "trained_weights = [weights_T1, weights_T2]\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"Amostra\", \"x1\", \"x2\", \"x3\", \"y (T1)\", \"y (T2)\"])\n",
    "\n",
    "# Função para classificar novas amostras\n",
    "def classify_samples(samples, weights):\n",
    "    predictions = np.sign(np.dot(samples, weights[1:]) + weights[0])  # Operação vetorizada\n",
    "    return predictions\n",
    "\n",
    "# Classificar novas amostras para cada treinamento e armazenar no DataFrame\n",
    "all_predictions = []\n",
    "\n",
    "# Classificar novas amostras para cada treinamento\n",
    "for i, weights in enumerate(trained_weights):\n",
    "    predictions = classify_samples(new_samples, weights)\n",
    "    all_predictions.append(predictions)\n",
    "    print(f\"Classificações usando o treinamento T{i+1}: {predictions}\")\n",
    "\n",
    "# Preenchendo o DataFrame\n",
    "for i, sample in enumerate(new_samples):\n",
    "    new_row = {\n",
    "        \"Amostra\": f\"A{i+1}\",\n",
    "        \"x1\": sample[0],\n",
    "        \"x2\": sample[1],\n",
    "        \"x3\": sample[2],\n",
    "        \"y (T1)\": all_predictions[0][i],\n",
    "        \"y (T2)\": all_predictions[1][i],\n",
    "    }\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# Exibir DataFrame de resultados da classificação\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Explique por que o número de épocas de treinamento varia a cada vez que se executa o treinamento do perceptron.**  \n",
    "\n",
    "Fatores como inicialização de pesos, ordem dos dados, taxa de aprendizado e critérios de convergência contribuem para a variação no número de épocas necessárias para treinar o modelo. No caso específico deste algorítmo, é devido à aleatoriedade dos pesos iniciais.\n",
    "\n",
    "**e. Qual é a principal limitação do perceptron quando aplicado em problemas de classificação de padrões?**  \n",
    "\n",
    "A maior limitação do Perceptron é sua incapacidade de resolver problemas que não são linearmente separáveis. Isso significa que se os dados não podem ser separados por uma única linha reta (em 2D), um plano (em 3D), ou um hiperplano (em mais de três dimensões), o Perceptron não será capaz de encontrar um conjunto de pesos que atinja zero erros no conjunto de treinamento.\n",
    "\n",
    "Esta limitação foi uma das principais razões para o declínio inicial do interesse em redes neurais nos anos 60, especialmente após a publicação do livro \"Perceptrons\" por Marvin Minsky e Seymour Papert, que provou matematicamente essa limitação para o Perceptron de camada única.\n",
    "\n",
    "Para solucionar problemas que não são linearmente separáveis, são necessárias estratégias mais complexas, como a inclusão de camadas ocultas para formar uma rede neural multicamadas (Multilayer Perceptron, MLP) e a aplicação de algoritmos de otimização mais sofisticados, como o backpropagation.\n",
    "\n",
    "Além da limitação de só poder resolver problemas linearmente separáveis, o perceptron também tem outras limitações, como:\n",
    "\n",
    "- Pode ser lento para treinar, especialmente para conjuntos de dados grandes;\n",
    "- Pode ser instável, dependendo da inicialização dos pesos;\n",
    "- Pode ser suscetível a overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Um sistema de gerenciamento automático de controle de duas válvulas, situado a 500 metros de um processo industrial, envia um sinal codificado constituído de quatro grandezas {x1, x2, x3 e x4} que são necessárias para o ajuste de cada uma das válvulas. Conforme mostra a figura abaixo, a mesma via de comunicação é utilizada para acionamento de ambas as válvulas, sendo que o comutador localizado próximo das válvulas deve decidir se o sinal é para a válvula A ou B. Porém, durante a transmissão, os sinais sofrem interferências que alteram o conteúdo das informações transmitidas. Para resolver este problema, treinar-se-á uma rede ADALINE para classificar os sinais ruidosos, que informará ao sistema comutador se os dados devem ser encaminhados para o comando de ajuste da válvula A ou B.**\n",
    "\n",
    "**Assim, baseado nas medições dos sinais já com ruídos, formou-se o conjunto de treinamento no arquivo `tab_treinamento2.dat`, tomando por convenção o valor –1 para os sinais que devem ser encaminhados para o ajuste da válvula A e o valor +1 se os mesmos devem ser enviados para a válvula B.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daí, pede-se:\n",
    "\n",
    "**a. Execute 2 treinamentos para a rede ADALINE inicializando o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos.**  \n",
    "**b. Registre os resultados dos 2 treinamentos acima na tabela abaixo:**  \n",
    "**c. Para os treinamentos realizados, aplique então a rede ADALINE para classificar e informar ao comutador se os sinais seguintes devem ser encaminhados para a válvula A ou B (ver tab_teste2.dat).**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo ada1: 94.12%\n",
      "Acurácia do modelo ada2: 91.18%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados dos pesos treinamento:\n",
      "  Treinamento  Número de Épocas  Inicial_w0  Inicial_w1  Inicial_w2   \n",
      "0        ADA1               500    0.682450    0.714602    0.887183  \\\n",
      "1        ADA2               500    0.389884    0.338751    0.266017   \n",
      "\n",
      "   Inicial_w3  Inicial_w4      Final_w0  Final_w1  Final_w2  Final_w3   \n",
      "0    0.428608    0.076276  2.102006e-08  0.529943  1.301589 -0.165739  \\\n",
      "1    0.814673    0.118989  1.200879e-08  0.503726  1.196799 -0.168158   \n",
      "\n",
      "   Final_w4  \n",
      "0 -1.625040  \n",
      "1 -1.523236  \n",
      "[[ 0.9209311   0.10565261 -0.86389912  0.6099808 ]\n",
      " [ 0.0188575   0.61740665 -0.02256117  0.93543358]\n",
      " [ 0.15711767 -1.08484267 -0.21284432 -1.44103024]\n",
      " [-1.4705047  -0.05808208 -1.80672141  0.31709142]\n",
      " [-0.73311714 -0.59563449 -0.13141131 -0.43011482]\n",
      " [-0.09445664 -0.79507294 -0.84589383 -1.11340254]\n",
      " [-0.32996402  1.08436465  0.40015386  0.54757264]\n",
      " [ 1.3023093  -0.70570264 -1.62707776 -0.54387528]\n",
      " [ 0.84292193  0.40436676  1.60159755  0.52697131]\n",
      " [-0.05872886  0.57933741  1.13632457  0.74343637]\n",
      " [-1.02337893 -1.93197561 -0.13141131 -1.90024067]\n",
      " [-0.28197464  2.20943998  1.35893539  1.73169637]\n",
      " [-1.52462489  0.58125935 -0.43831961  0.44227021]\n",
      " [-0.05872886  0.57933741  1.13632457  0.74343637]\n",
      " [ 2.33334116 -0.98985438  0.44680392 -1.16922552]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>Predição ADA1</th>\n",
       "      <th>Predição ADA2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.920931</td>\n",
       "      <td>0.105653</td>\n",
       "      <td>-0.863899</td>\n",
       "      <td>0.609981</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018858</td>\n",
       "      <td>0.617407</td>\n",
       "      <td>-0.022561</td>\n",
       "      <td>0.935434</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.157118</td>\n",
       "      <td>-1.084843</td>\n",
       "      <td>-0.212844</td>\n",
       "      <td>-1.441030</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.470505</td>\n",
       "      <td>-0.058082</td>\n",
       "      <td>-1.806721</td>\n",
       "      <td>0.317091</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.733117</td>\n",
       "      <td>-0.595634</td>\n",
       "      <td>-0.131411</td>\n",
       "      <td>-0.430115</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.094457</td>\n",
       "      <td>-0.795073</td>\n",
       "      <td>-0.845894</td>\n",
       "      <td>-1.113403</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.329964</td>\n",
       "      <td>1.084365</td>\n",
       "      <td>0.400154</td>\n",
       "      <td>0.547573</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.302309</td>\n",
       "      <td>-0.705703</td>\n",
       "      <td>-1.627078</td>\n",
       "      <td>-0.543875</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.842922</td>\n",
       "      <td>0.404367</td>\n",
       "      <td>1.601598</td>\n",
       "      <td>0.526971</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.058729</td>\n",
       "      <td>0.579337</td>\n",
       "      <td>1.136325</td>\n",
       "      <td>0.743436</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.023379</td>\n",
       "      <td>-1.931976</td>\n",
       "      <td>-0.131411</td>\n",
       "      <td>-1.900241</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.281975</td>\n",
       "      <td>2.209440</td>\n",
       "      <td>1.358935</td>\n",
       "      <td>1.731696</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.524625</td>\n",
       "      <td>0.581259</td>\n",
       "      <td>-0.438320</td>\n",
       "      <td>0.442270</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.058729</td>\n",
       "      <td>0.579337</td>\n",
       "      <td>1.136325</td>\n",
       "      <td>0.743436</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.333341</td>\n",
       "      <td>-0.989854</td>\n",
       "      <td>0.446804</td>\n",
       "      <td>-1.169226</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2        x3        x4 Predição ADA1 Predição ADA2\n",
       "0   0.920931  0.105653 -0.863899  0.609981             A             A\n",
       "1   0.018858  0.617407 -0.022561  0.935434             A             A\n",
       "2   0.157118 -1.084843 -0.212844 -1.441030             B             B\n",
       "3  -1.470505 -0.058082 -1.806721  0.317091             A             A\n",
       "4  -0.733117 -0.595634 -0.131411 -0.430115             A             A\n",
       "5  -0.094457 -0.795073 -0.845894 -1.113403             B             B\n",
       "6  -0.329964  1.084365  0.400154  0.547573             B             B\n",
       "7   1.302309 -0.705703 -1.627078 -0.543875             B             B\n",
       "8   0.842922  0.404367  1.601598  0.526971             A             A\n",
       "9  -0.058729  0.579337  1.136325  0.743436             A             A\n",
       "10 -1.023379 -1.931976 -0.131411 -1.900241             B             B\n",
       "11 -0.281975  2.209440  1.358935  1.731696             A             A\n",
       "12 -1.524625  0.581259 -0.438320  0.442270             A             A\n",
       "13 -0.058729  0.579337  1.136325  0.743436             A             A\n",
       "14  2.333341 -0.989854  0.446804 -1.169226             B             B"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **a. Execute 2 treinamentos para a rede ADALINE inicializando o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos.**  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_sistema = np.loadtxt('tab_treinamento2.dat')\n",
    "df = pd.DataFrame(data_sistema)\n",
    "\n",
    "# Outliers\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# Valores abaixo de Q1 - 1.5 * IQR ou acima de Q3 + 1.5 * IQR são considerados outliers.\n",
    "outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).sum()\n",
    "\n",
    "# Identificando os limites para outliers na coluna 3\n",
    "lower_bound_col3 = Q1[3] - 1.5 * IQR[3]\n",
    "upper_bound_col3 = Q3[3] + 1.5 * IQR[3]\n",
    "\n",
    "# Mantendo apenas as linhas onde os valores na coluna 3 não são outliers\n",
    "df = df[(df.iloc[:, 3] >= lower_bound_col3) & (df.iloc[:, 3] <= upper_bound_col3)]\n",
    "\n",
    "X = df.iloc[:, 0:4].values  # Entradas\n",
    "y = df.iloc[:, 4].values  # Saídas\n",
    "\n",
    "# Padronização dos dados\n",
    "# Normalização das características de entrada usando o método Z-score\n",
    "mean = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "X_std = (X - mean) / std\n",
    "# Modelo ADALINE\n",
    "class AdalineGD:\n",
    "    def __init__(self, eta=0.01, epochs=50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, X, y, reinitialize_weights=True):\n",
    "        if reinitialize_weights:\n",
    "            self.w_ = np.random.rand(1 + X.shape[1])\n",
    "            self.initial_weights_ = np.copy(self.w_)\n",
    "        \n",
    "        self.cost_ = []\n",
    "        self.previous_cost_ = float('inf')  # inicializar com um valor infinito\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            output = self.net_input(X)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "            \n",
    "            # Se o custo começar a aumentar, interromper o treinamento\n",
    "            if cost > self.previous_cost_:\n",
    "                print(f\"Treinamento interrompido na época {i + 1} devido ao aumento do erro.\")\n",
    "                break\n",
    "\n",
    "            self.previous_cost_ = cost\n",
    "\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        return self.net_input(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation(X) >= 0.0, 1, -1)\n",
    "\n",
    "\n",
    "# Treinamento\n",
    "###############\n",
    "eta = 0.001\n",
    "epochs = 500\n",
    "\n",
    "# Primeiro treinamento\n",
    "ada1 = AdalineGD(eta, epochs)\n",
    "ada1.train(X_std, y)\n",
    "\n",
    "# Segundo treinamento\n",
    "ada2 = AdalineGD(eta, epochs)\n",
    "ada2.train(X_std, y)\n",
    "\n",
    "## Acurácia\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / total\n",
    "\n",
    "# Para modelo ada1\n",
    "predictions_ada1 = ada1.predict(X_std)\n",
    "accuracy_ada1 = accuracy(y, predictions_ada1)\n",
    "\n",
    "# Para modelo ada2\n",
    "predictions_ada2 = ada2.predict(X_std)\n",
    "accuracy_ada2 = accuracy(y, predictions_ada2)\n",
    "\n",
    "print(f\"Acurácia do modelo ada1: {accuracy_ada1 * 100:.2f}%\")\n",
    "print(f\"Acurácia do modelo ada2: {accuracy_ada2 * 100:.2f}%\")\n",
    "\n",
    "# Convergência (Através do Custo)\n",
    "# A convergência do modelo pode ser visualizada examinando a diminuição do custo durante cada época. Se o modelo estiver aprendendo corretamente, o custo deve diminuir à medida que as épocas avançam.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "# Plotando o custo para ada1\n",
    "plt.plot(range(1, len(ada1.cost_) + 1), ada1.cost_, marker='o', label='ADA1')\n",
    "\n",
    "# Plotando o custo para ada2\n",
    "plt.plot(range(1, len(ada2.cost_) + 1), ada2.cost_, marker='x', label='ADA2', linestyle='--')\n",
    "\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Soma dos Erros Quadrados (SE)')\n",
    "plt.legend()\n",
    "plt.title('Convergência da Rede ADALINE')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#**b. Registre os resultados dos 2 treinamentos acima na tabela abaixo:**\n",
    "\n",
    "# Dados para o primeiro treinamento (ada1)\n",
    "initial_weights_ada1 = ada1.initial_weights_\n",
    "final_weights_ada1 = ada1.w_\n",
    "epochs_ada1 = len(ada1.cost_)\n",
    "\n",
    "# Dados para o segundo treinamento (ada2)\n",
    "initial_weights_ada2 = ada2.initial_weights_\n",
    "final_weights_ada2 = ada2.w_\n",
    "epochs_ada2 = len(ada2.cost_)\n",
    "\n",
    "# Inserir os dados no DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"Treinamento\": [\"ADA1\", \"ADA2\"],\n",
    "    \"Vetor de Pesos Inicial\": [initial_weights_ada1, initial_weights_ada2],\n",
    "    \"Vetor de Pesos Final\": [final_weights_ada1, final_weights_ada2],\n",
    "    \"Número de Épocas\": [epochs_ada1, epochs_ada2]\n",
    "})\n",
    "\n",
    "# Separa o vetor inicial em colunas distintas\n",
    "weights_initial_df = results_df['Vetor de Pesos Inicial'].apply(pd.Series)\n",
    "weights_initial_df = weights_initial_df.rename(columns=lambda x: f'Inicial_w{x}')\n",
    "\n",
    "# Separa o vetor final em colunas distintas\n",
    "weights_final_df = results_df['Vetor de Pesos Final'].apply(pd.Series)\n",
    "weights_final_df = weights_final_df.rename(columns=lambda x: f'Final_w{x}')\n",
    "\n",
    "# Concatena com o dataframe original\n",
    "results_df = pd.concat([results_df.drop(columns=['Vetor de Pesos Inicial', 'Vetor de Pesos Final']), weights_initial_df, weights_final_df], axis=1)\n",
    "\n",
    "print(\"Resultados dos pesos treinamento:\")\n",
    "print(results_df)\n",
    "\n",
    "# **c. Para os treinamentos realizados, aplique então a rede ADALINE para classificar e informar ao comutador se os sinais seguintes devem ser encaminhados para a válvula A ou B (ver tab_teste2.dat).**\n",
    "\n",
    "data_teste = np.loadtxt('tab_teste2.dat')\n",
    "X_test = data_teste[:, 0:4]  # sinais de entrada\n",
    "# Padronização dos dados\n",
    "# Normalização das características de entrada usando o método Z-score\n",
    "mean_test = X_test.mean(axis=0)\n",
    "std_test = X_test.std(axis=0)\n",
    "X_std_test = (X_test - mean_test) / std_test\n",
    "\n",
    "print(X_std_test)\n",
    "\n",
    "predictions_ada1 = ada1.predict(X_std_test)\n",
    "#print(f\"Modelo 1 {predictions_ada1}\")\n",
    "predictions_ada2 = ada2.predict(X_std_test)\n",
    "#print(f\"Modelo 2 {predictions_ada2}\")\n",
    "\n",
    "results_test_df = pd.DataFrame(X_std_test, columns=[\"x1\", \"x2\", \"x3\", \"x4\"])\n",
    "results_test_df[\"Predição ADA1\"] = predictions_ada1\n",
    "results_test_df[\"Predição ADA2\"] = predictions_ada2\n",
    "\n",
    "# Convertendo os valores para 'A' e 'B' para melhor visualização\n",
    "results_test_df[\"Predição ADA1\"] = results_test_df[\"Predição ADA1\"].apply(lambda x: 'A' if x == -1 else 'B')\n",
    "results_test_df[\"Predição ADA2\"] = results_test_df[\"Predição ADA2\"].apply(lambda x: 'A' if x == -1 else 'B')\n",
    "\n",
    "results_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Um(a) estudante da disciplina de Redes Neurais e Aprendizado Profundo ficou empolgado(a) com o trabalho do Fisher sobre as flores Íris e resolveu propor uma versão automatizada para ele. Essa nova versão deveria ter dois módulos principais: um módulo de visão computacional e um módulo do tipo classificador neural. Caso você(s) fosse(m) esse(a) estudante, como você(s) desenvolveria(m) esse sistema? Descreva-o em detalhes. Use ilustração(ões) para valorizar o seu pré-projeto. Lembre-se que são três tipos de Íris (Virginica, Versicolor e Setosa) e que 4 parâmetros foram medidos pelo Fisher para cada uma das flores (comprimento e largura da Pétala, Comprimento e largura da Sépala).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O projeto pode ser encontrado no link: (https://docs.google.com/document/d/1oAT9ueBM05FFpA8k3NKCb3u1_8dOVWDOJTld1i-VdRs/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Considere a base de dados encontrada em Irisdat.xlsx. Daí, pede-se:**  \n",
    "**a) Treinar um PMC que classifique observações de flores íris em 3 espécies (Setosa, Versicolor e Virginica) usando como entradas as características SEPALLENGTH (SL), SEPALWIDTH (SW), PETALLENGTH (PL) e PETALWIDTH (PW).**  \n",
    "**b) Estime SL a partir de SW, PL, PW.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SL</th>\n",
       "      <th>SW</th>\n",
       "      <th>PL</th>\n",
       "      <th>PW</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>SETOSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>VIRGINIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>VERSICOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>VIRGINIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>VIRGINIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SL   SW   PL   PW      TYPE\n",
       "0  5.0  3.3  1.4  0.2    SETOSA\n",
       "1  6.4  2.8  5.6  2.2  VIRGINIC\n",
       "2  6.5  2.8  4.6  1.5  VERSICOL\n",
       "3  6.7  3.1  5.6  2.4  VIRGINIC\n",
       "4  6.3  2.8  5.1  1.5  VIRGINIC"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregando os dados\n",
    "data = pd.read_excel(\"Irisdat.xlsx\")\n",
    "# Selecionando apenas as colunas desejadas\n",
    "selected_columns = ['SL', 'SW', 'PL', 'PW', 'TYPE']\n",
    "filtered_df = data[selected_columns].dropna()\n",
    "filtered_df = pd.DataFrame(data, columns=['SL', 'SW', 'PL', 'PW', 'TYPE'])\n",
    "for col in ['SL', 'SW', 'PL', 'PW']:\n",
    "    filtered_df[col] = pd.to_numeric(filtered_df[col], errors='coerce')\n",
    "\n",
    "filtered_df = filtered_df.dropna()\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 14ms/step - loss: 1.1771 - accuracy: 0.4522 - val_loss: 1.1821 - val_accuracy: 0.4828\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.1159 - accuracy: 0.5304 - val_loss: 1.1190 - val_accuracy: 0.4828\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0615 - accuracy: 0.5217 - val_loss: 1.0606 - val_accuracy: 0.4828\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0140 - accuracy: 0.5217 - val_loss: 1.0037 - val_accuracy: 0.3793\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9676 - accuracy: 0.4957 - val_loss: 0.9535 - val_accuracy: 0.3793\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9245 - accuracy: 0.4957 - val_loss: 0.9110 - val_accuracy: 0.4483\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8882 - accuracy: 0.4783 - val_loss: 0.8664 - val_accuracy: 0.4828\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8507 - accuracy: 0.4870 - val_loss: 0.8305 - val_accuracy: 0.5862\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8206 - accuracy: 0.5391 - val_loss: 0.7949 - val_accuracy: 0.5517\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7907 - accuracy: 0.5652 - val_loss: 0.7628 - val_accuracy: 0.6552\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7627 - accuracy: 0.6609 - val_loss: 0.7339 - val_accuracy: 0.7241\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7377 - accuracy: 0.6261 - val_loss: 0.7084 - val_accuracy: 0.7586\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7160 - accuracy: 0.6696 - val_loss: 0.6850 - val_accuracy: 0.7241\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.6696 - val_loss: 0.6653 - val_accuracy: 0.7241\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.6783 - val_loss: 0.6472 - val_accuracy: 0.7931\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.6870 - val_loss: 0.6296 - val_accuracy: 0.7931\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6870 - val_loss: 0.6146 - val_accuracy: 0.7931\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6783 - val_loss: 0.6008 - val_accuracy: 0.7931\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.6783 - val_loss: 0.5873 - val_accuracy: 0.7931\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6957 - val_loss: 0.5743 - val_accuracy: 0.7931\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6957 - val_loss: 0.5635 - val_accuracy: 0.7931\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5853 - accuracy: 0.7130 - val_loss: 0.5532 - val_accuracy: 0.7931\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7130 - val_loss: 0.5441 - val_accuracy: 0.7931\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7130 - val_loss: 0.5355 - val_accuracy: 0.7931\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7217 - val_loss: 0.5274 - val_accuracy: 0.7931\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7304 - val_loss: 0.5199 - val_accuracy: 0.7931\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7304 - val_loss: 0.5124 - val_accuracy: 0.8276\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7304 - val_loss: 0.5056 - val_accuracy: 0.8276\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7391 - val_loss: 0.4982 - val_accuracy: 0.8276\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5242 - accuracy: 0.7739 - val_loss: 0.4924 - val_accuracy: 0.8276\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7739 - val_loss: 0.4866 - val_accuracy: 0.8276\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7739 - val_loss: 0.4811 - val_accuracy: 0.8276\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7739 - val_loss: 0.4755 - val_accuracy: 0.8276\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7913 - val_loss: 0.4708 - val_accuracy: 0.8276\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7913 - val_loss: 0.4653 - val_accuracy: 0.8276\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.8000 - val_loss: 0.4606 - val_accuracy: 0.8276\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.8000 - val_loss: 0.4565 - val_accuracy: 0.8276\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.8087 - val_loss: 0.4514 - val_accuracy: 0.8276\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8087 - val_loss: 0.4466 - val_accuracy: 0.8276\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8087 - val_loss: 0.4423 - val_accuracy: 0.8276\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.8087 - val_loss: 0.4384 - val_accuracy: 0.8276\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.8087 - val_loss: 0.4340 - val_accuracy: 0.8276\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8087 - val_loss: 0.4296 - val_accuracy: 0.8276\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.8174 - val_loss: 0.4258 - val_accuracy: 0.8276\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.8174 - val_loss: 0.4220 - val_accuracy: 0.8276\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.8174 - val_loss: 0.4179 - val_accuracy: 0.8276\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8174 - val_loss: 0.4136 - val_accuracy: 0.8276\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.8174 - val_loss: 0.4102 - val_accuracy: 0.8276\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.8174 - val_loss: 0.4067 - val_accuracy: 0.8276\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8174 - val_loss: 0.4028 - val_accuracy: 0.8276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x204cd7b5e50>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "# Preparando os dados\n",
    "X = filtered_df[['SL', 'SW', 'PL', 'PW']].values\n",
    "y = filtered_df['TYPE'].values.reshape(-1, 1)\n",
    "\n",
    "# Codificando a saída\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Construindo o PMC\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Estime SL a partir de SW, PL, PW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 33.3526 - val_loss: 34.0184\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.1132 - val_loss: 32.8017\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 30.8941 - val_loss: 31.6276\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 29.7168 - val_loss: 30.4575\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 28.5809 - val_loss: 29.2934\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 27.4418 - val_loss: 28.1845\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 26.3441 - val_loss: 27.0903\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 25.2547 - val_loss: 26.0054\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 24.2053 - val_loss: 24.9311\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 23.1618 - val_loss: 23.8716\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 22.1419 - val_loss: 22.8354\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 21.1634 - val_loss: 21.8124\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 20.1713 - val_loss: 20.8501\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 19.2390 - val_loss: 19.8954\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 18.3298 - val_loss: 18.9458\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 17.4494 - val_loss: 18.0197\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 16.5945 - val_loss: 17.1536\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.7858 - val_loss: 16.3091\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 15.0067 - val_loss: 15.4792\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 14.2456 - val_loss: 14.7028\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 13.5302 - val_loss: 13.9380\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.8366 - val_loss: 13.2193\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 12.1895 - val_loss: 12.5082\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 11.5617 - val_loss: 11.8393\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.9778 - val_loss: 11.2110\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 10.4467 - val_loss: 10.6004\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.9215 - val_loss: 10.0483\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 9.4431 - val_loss: 9.5118\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.9894 - val_loss: 9.0060\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.5735 - val_loss: 8.5186\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 8.1790 - val_loss: 8.0496\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.8082 - val_loss: 7.6187\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.4708 - val_loss: 7.2140\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 7.1532 - val_loss: 6.8547\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.8738 - val_loss: 6.5142\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.6158 - val_loss: 6.1959\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.3757 - val_loss: 5.8913\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 6.1371 - val_loss: 5.6177\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.9224 - val_loss: 5.3595\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.7088 - val_loss: 5.0961\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.4822 - val_loss: 4.8646\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.2913 - val_loss: 4.6316\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 5.0889 - val_loss: 4.4213\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.9112 - val_loss: 4.2060\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.7202 - val_loss: 4.0248\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.5499 - val_loss: 3.8376\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.3665 - val_loss: 3.6777\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.2082 - val_loss: 3.5068\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 4.0502 - val_loss: 3.3485\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.8965 - val_loss: 3.1951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x204cd805690>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparando os dados de regressão\n",
    "X_reg = filtered_df[['SW', 'PL', 'PW']].values\n",
    "y_reg = filtered_df['SL'].values.reshape(-1, 1)\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizando os dados de regressão\n",
    "scaler_reg = StandardScaler().fit(X_train_reg)\n",
    "X_train_reg = scaler_reg.transform(X_train_reg)\n",
    "X_test_reg = scaler_reg.transform(X_test_reg)\n",
    "\n",
    "# Construindo o modelo de regressão\n",
    "reg_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(3,)),  # Temos 3 entradas agora: SW, PL, PW\n",
    "    tf.keras.layers.Dense(1)  # A saída é um valor único, SL\n",
    "])\n",
    "\n",
    "# Compilando o modelo de regressão\n",
    "reg_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Treinando o modelo de regressão\n",
    "reg_model.fit(X_train_reg, y_train_reg, epochs=50, batch_size=10, validation_data=(X_test_reg, y_test_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Considere a base de dados encontrada em engines.xlsx, em que ‘Fuel rate’ e ‘Speed’ são variáveis de entrada e ‘Torque’ e ‘Nitrous Oxide Emissions (NOE)’ são as variáveis de saída, respectivamente. Desenvolva três regressores. Um deles deve estimar conjuntamente o ‘Torque’ e o NOE. Já os outros dois devem estimar essas saídas separadamente (i.e. um estimará o Torque e o outro o NOE). Compare o desempenho das duas estratégias apontando qual delas apresenta uma maior capacidade de generalização.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0066\n",
      "8/8 [==============================] - 0s 857us/step - loss: 0.0012\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Loss do regressor conjunto: 0.006613506469875574\n",
      "Loss do regressor torque: 0.001184589695185423\n",
      "Loss do regressor noe: 0.015219268389046192\n"
     ]
    }
   ],
   "source": [
    "#Regressor para estimar conjuntamente o `Torque` e o `NOE``\n",
    "#Regressor para estimar apenas o `Torque`\n",
    "#Regressor para estimar apenas o `NOE`\n",
    "#Comparação\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Carregando e transpondo os dados\n",
    "data_engine = pd.read_excel(\"engines-tratado.xlsx\")\n",
    "\n",
    "# Preparação dos dados\n",
    "X = data_engine[['fuel_rate', 'speed']]\n",
    "y = data_engine[['torque', 'noe']]\n",
    "\n",
    "# Divisão dos dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalização dos dados\n",
    "scaler_X = StandardScaler().fit(X_train)\n",
    "X_train = scaler_X.transform(X_train)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler().fit(y_train)\n",
    "y_train = scaler_y.transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "# Construindo o regressor conjunto\n",
    "model_conjunto = Sequential([\n",
    "    Dense(32, activation='relu', input_dim=2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='linear')  # Duas saídas: torque e noe\n",
    "])\n",
    "model_conjunto.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Treinamento do regressor conjunto\n",
    "model_conjunto.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Avaliação do regressor conjunto\n",
    "loss_conjunto = model_conjunto.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Construindo e treinando regressores individuais\n",
    "outputs = ['torque', 'noe']\n",
    "losses = {}\n",
    "for output in outputs:\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_dim=2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    y_train_single = y_train[:, outputs.index(output)]\n",
    "    y_test_single = y_test[:, outputs.index(output)]\n",
    "    model.fit(X_train, y_train_single, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
    "    losses[output] = model.evaluate(X_test, y_test_single, verbose=1)\n",
    "\n",
    "# Comparando o desempenho\n",
    "print(f\"Loss do regressor conjunto: {loss_conjunto}\")\n",
    "for output, loss in losses.items():\n",
    "    print(f\"Loss do regressor {output}: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Loss do regressor conjunto: 0.006613506469875574** \n",
    "   \n",
    "   Este valor refere-se à perda de um modelo que tenta prever ambas as saídas (\"Torque\" e \"NOE\") simultaneamente. O valor é relativamente baixo, mas para avaliar se é realmente bom, é preciso comparar com uma baseline ou benchmark adequado.\n",
    "\n",
    "2. **Loss do regressor torque: 0.001184589695185423** \n",
    "   \n",
    "   Este valor é significativamente menor do que o regressor conjunto, indicando que este modelo específico que prevê somente o \"Torque\" é mais preciso (ou tem menos erro) do que o regressor conjunto, pelo menos no que diz respeito à variável \"Torque\".\n",
    "\n",
    "3. **Loss do regressor noe: 0.015219268389046192** \n",
    "   \n",
    "   Este valor é o mais alto entre os três. Indica que o modelo que prevê somente \"NOE\" tem o maior erro entre os modelos apresentados. É quase 2,3 vezes maior do que o erro do regressor conjunto e muito maior do que o erro do regressor de torque.\n",
    "\n",
    "Em resumo:\n",
    "\n",
    "- O modelo para \"Torque\" parece ser o mais preciso.\n",
    "- O modelo para \"NOE\" parece ser o menos preciso.\n",
    "- O modelo conjunto, que tenta prever ambas as saídas simultaneamente, fica entre os dois em termos de precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Valendo-se da base de dados reais referente ao Volume de Vendas de Passagens (VVP) de uma companhia aérea norte-americana que se encontra no arquivo vvp.xlsx, pede-se:**  \n",
    "\n",
    "**1) Desenvolver um previsor neural que receba como entradas os VVPs registrados nos instantes k-1 e k-12 (i.e. VVP(k-1) e VVP(k-12)) e que disponibilize na saída o VVP no instante corrente k (i.e. VVP(k)). O previsor deverá 4 realizar previsões recursivas de 1 a 12 passos à frente (i.e., de um a doze meses à frente);**  \n",
    "\n",
    "**2) De posse da base de dados, remova a tendência linear presente na base de dados original. Desse modo, você conhecerá a série destendenciada e a tendência linear. Para a primeira série, desenvolva um previsor neural que receba como entradas os VVPs registrados nos instantes k-1 e k-12 (i.e. VVP(k-1) e VVP(k-12)) e que disponibilize na saída o VVP no instante corrente k (i.e. VVP(k)). O previsor deverá realizar previsões recursivas de 1 a 12 passos à frente (i.e., de um a doze meses à frente). Para a segunda (i.e., a tendência linear), preveja linearmente os próximos dozes pontos. Em seguida, some ponto a ponto as duas previsões e compare o desempenho dessa abordagem com a anterior apontando qual delas apresenta uma maior capacidade de generalização.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Procure na literatura 2 artigos que tratem do tema Sensores Inferenciais (ou Soft Sensors) para uma dada grandeza de seu interesse (e.g. temperatura, pressão, vazão, nível etc.) e que tenham sido publicados nos últimos 5 anos. Explique de forma sucinta o que foi desenvolvido pelos autores, referenciando-os. Sugestão: As principais informações de qualquer artigo geralmente se encontram no título, no resumo e nas conclusões. Ao ler esses três itens, o leitor tem uma boa ideia do que esperar daquele trabalho. A propósito, usualmente o leitor decidirá se lerá todo o artigo ou não com base na sua impressão a respeito desses três itens.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A grandeza escolhida foi temperatura, por ser extremamente difícil de realizar sua predição em situações adversas. Para tais situação, selecionamos os seguintes artigos:\n",
    "\n",
    "- XU, Feng et al. **Soft-Sensor Modeling of Temperature Variation in a Room under Cooling Conditions**. Energies, 2023. \"[DOI 10.3390/en16062870](https://github.com/alexandrefortes/redes-neurais/blob/9c2c6481117a6ddcbf3739ba679dca07daaa98c3/article%20-%20Feng%20Xu%20-%202023%20-%20Soft-Sensor%20Modeling%20of%20Temperature%20Variation%20in%20a%20Room%20under%20Cooling%20Conditions.pdf)\".\n",
    "- DUAN, Yanhui et al. **A Dynamic Time Warping Based Locally Weighted LSTM Modeling for Temperature Prediction of Recycled Aluminum Smelting**. IEEE Access, 2023 \"[DOI 10.1109/ACCESS.2023.3266518](https://github.com/alexandrefortes/redes-neurais/blob/9c2c6481117a6ddcbf3739ba679dca07daaa98c3/article%20-%20Duan%20-%202023%20-%20A_Dynamic_Time_Warping_Based_Locally_Weighted_LSTM_Modeling_for_Temperature_Prediction_of_Recycled_Aluminum_Smelting.pdf)\".  \n",
    "\n",
    "O primeiro, trabalho do XU et al., da modelagem de um sensor inferencial da medição de temperatura em uma sala sob condições de resfriamento, conseguiram um resultado muito bom em que o modelo de cada local alvo - que foram diversos nos aparelhos de utilizados para aquecer, resfriar e ventilar o ar do ambiente; demonstraram uma boa precisão, com os valores de Erro Absoluto Médio (MAE) dentro de 0,69 Kelvin para várias temperaturas iniciais (de 25 a 35 °C) e de vazão inicial (de 770 a 850 mL/min). O resultado do modelo do sensor inferencial foi desenvolvido utilizando o médo de regressão linear múltipla, após XU et al. analisarem outros trabalhos semelhantes em que utilizam redes neurais artificials, aprendizagem profunda e modelos de regressão linear, que estes estudos incorporam menos mecanismos de processo na construção e análise de modelos de sensores inferenciais usados em áreas de ar condicionado. Entretanto, apesar do modelo prever com precisão as temperaturas locais mantendo uma gestão eficiente da energia e do conforto, também no resfiamento do ambiente, XU et al ressalta avaliar o desempenho do modelo do sensor inferencial de temperatura para os modos de aquecimento.\n",
    "\n",
    "Já no segundo, trabalho do DUAN et al., cujo a complexidade está inclusa desde o título ao propor um modelo para medir a similaridade entre duas sequências temporais - que podem ter velocidade assíncrona; através de uma rede neural recorrente LSTM, capaz de aprender com o tempo, e ponderada para prever a temperatura em um processo de alumínio reciclado. Para eles lidarem com os problemas na previsão da temperatura do forno de um forno de fundição de alumínio regenerativo, é proposto um método de modelagem de sensor suave baseado em DFC-DLWLSTM. Este método de modelagem extrai completamente as características temporais dos dados usando redes neurais LSTM. Eles definiram isso ao perceberem pela literatura que as redes neurais artificiais (ANN) são promissoras para a modelagem de sensores inferenciais para uma estrutura estática. Entretanto, se utilizassem uma rede neural recorrente (RNN) sanaria a questão se não fosse pelo fato dela ser sensível a explosão ou ausência de gradiente ao lidar com série temporais, daí a escolha da rede neural de memória de longo prazo (LSTM). Isso tudo para selecionar para o como base para o trabalho um modelo LSTM ponderado para a distorção de tempo dinâmico (DTW) e propor um modelo de classificação de condição de operação e previsão composto por um algoritmo de c-means difuso (FCM) baseando em distorção de tempo dinâmico (DTW) e rede neural convolucional (CNN) que é denotado como DFC. Daí o modelo DFC-DLWLSTM. O modelo local para as amostras de consulta é construído considerando os pesos de diferentes amostras de entrada históricas. Isso não só resolve o problema da variação de tempo, mas também extrai efetivamente as características não lineares das amostras de entrada. O modelo proposto por DUAN et al. foi testado usando dados reais de uma planta de fundição de alumínio e os resultados mostraram que ele funciona bem, confirmando assim a validade do método proposto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
