{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Especialização em Inteligência Artificial – IFMG\n",
    "# Trabalho da disciplina de Redes Neurais e Aprendizado Profundo\n",
    "Autor: Alexandre Fortes Santana\n",
    "\n",
    "Professor: Agnaldo José da Rocha Reis - UFOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. O que é inteligência para você?\n",
    "\n",
    "Para mim, inteligência poderia ser definida pelos tópicos a seguir:\n",
    "- Inteligência se manifesta em diferentes graus e tipos;\n",
    "- Inteligência se desenvolve em um indivíduo, a princípio, biológico;\n",
    "- O indivíduo detentor de inteligência em questão precisa ter a capacidade de memorizar informações em alguma escala;\n",
    "- O indivíduo detentor de inteligência utiliza as informações a que tem acesso para interpretar o mundo a sua volta e a si mesmo;\n",
    "- O indivíduo detentor de inteligência é capaz de decisões, agir e criar novos artefatos (imaginários ou físicos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Em sua opinião, o que aconteceria se alguém descobrisse como implementar uma IA mais abrangente (e.g., AGI) em um robô?\n",
    "A descoberta de uma Inteligência Artificial Geral seria um marco histórico para a humanidade. Experimentaríamos um período de frenesi nas redes sociais, nos noticiários e nas rodas de conversa. Muitos dilemas seriam discutidos, abordando temas como mercado de trabalho, impacto social, segurança, regulação, ética e questões militares. Os primeiros robôs focariam em demonstrar o potencial de suas aplicações e em realizar apresentações que alimentassem o frenesi público. Após um período marcado por medo, especulações e empolgação, veríamos as primeiras aplicações práticas direcionadas a problemas reais. Os primeiros robôs comerciais seriam mais simples, devido ao elevado custo de produção, e não necessariamente seriam humanoides. Não, não acredito que as máquinas se revoltariam, levando a um apocalipse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Análise de um processo de destilação fracionada de petróleo\n",
    "A partir da análise de um processo de destilação fracionada de petróleo observou-se que determinado óleo poderia ser classificado em duas classes de pureza {C1 e C2}, mediante a medição de três grandezas {x1, x2 e x3} que representam algumas das propriedades físico-químicas do óleo. Para tanto, pretende-se utilizar um perceptron para executar a classificação automática dessas duas classes. Assim, baseadas nas informações coletadas do processo, formou-se o conjunto de treinamento em anexo (vou te passar a estrutura de dados nas próximas mensagens), tomando por convenção o valor –1 para óleo pertencente à classe C1 e o valor +1 para óleo pertencente à classe C2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Execute dois treinamentos para a rede perceptron, inicializando-se o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergiu na época 433\n",
      "[0.87132654 0.55759443 0.15687519 0.4031135 ]\n",
      "[31.67132654 16.02395443 25.45669519 -7.5308065 ]\n",
      "433\n",
      "Convergiu na época 413\n",
      "[0.46835909 0.13546439 0.47693809 0.48523506]\n",
      "[31.06835909 15.60934439 25.07245809 -7.38660494]\n",
      "413\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Vetor de Pesos Inicial</th>\n",
       "      <th>Vetor de Pesos Final</th>\n",
       "      <th>Número de Épocas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.871327</td>\n",
       "      <td>31.671327</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.557594</td>\n",
       "      <td>16.023954</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.156875</td>\n",
       "      <td>25.456695</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.403114</td>\n",
       "      <td>-7.530806</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.468359</td>\n",
       "      <td>31.068359</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.135464</td>\n",
       "      <td>15.609344</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.476938</td>\n",
       "      <td>25.072458</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.485235</td>\n",
       "      <td>-7.386605</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Treinamento  Vetor de Pesos Inicial  Vetor de Pesos Final Número de Épocas\n",
       "0          T1                0.871327             31.671327              433\n",
       "1          T1                0.557594             16.023954              433\n",
       "2          T1                0.156875             25.456695              433\n",
       "3          T1                0.403114             -7.530806              433\n",
       "4          T2                0.468359             31.068359              413\n",
       "5          T2                0.135464             15.609344              413\n",
       "6          T2                0.476938             25.072458              413\n",
       "7          T2                0.485235             -7.386605              413"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = np.loadtxt('tab_treinamento1.dat')\n",
    "training_data = data[:, :3]\n",
    "labels = data[:, 3]\n",
    "\n",
    "# Bias: Adicionando uma coluna de uns ao conjunto de dados de treinamento\n",
    "training_data = np.c_[np.ones(training_data.shape[0]), training_data]\n",
    "\n",
    "epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Inicialização de pesos\n",
    "def initialize_weights(dim):\n",
    "    return np.random.rand(dim)\n",
    "\n",
    "# Treinamento do Perceptron\n",
    "def train_perceptron(training_data, labels, learning_rate, epochs):\n",
    "    # Inicialização de pesos\n",
    "    weights = initialize_weights(training_data.shape[1])\n",
    "    initial_weights = np.copy(weights)\n",
    "    no_errors = 0\n",
    "    final_epoch = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(training_data)):\n",
    "            x = training_data[i]\n",
    "            y = labels[i]\n",
    "            \n",
    "            # Cálculo do output e função de ativação\n",
    "            output = np.dot(weights, x)\n",
    "            prediction = 1 if output > 0 else -1\n",
    "\n",
    "            # Atualização de pesos\n",
    "            if prediction != y:\n",
    "                weights += learning_rate * (y - prediction) * x\n",
    "                no_errors += 1\n",
    "\n",
    "        if no_errors == 0:\n",
    "            final_epoch = epoch+1\n",
    "            print(f\"Convergiu na época {final_epoch}\")\n",
    "            break\n",
    "        no_errors = 0 # reseta contador de erros\n",
    "                \n",
    "    return initial_weights, weights, final_epoch\n",
    "\n",
    "# DataFrame para armazenar os resultados\n",
    "results_df = pd.DataFrame(columns=[\"Treinamento\", \"Vetor de Pesos Inicial\", \"Vetor de Pesos Final\", \"Número de Épocas\"])\n",
    "\n",
    "# Executando Dois Treinamentos\n",
    "for i in range(2):\n",
    "    initial_weights, final_weights, final_epoch = train_perceptron(training_data, labels, learning_rate, epochs)  \n",
    "    \n",
    "    print(initial_weights)\n",
    "    print(final_weights)\n",
    "    print(final_epoch)\n",
    "\n",
    "    new_row_df = pd.DataFrame({\n",
    "        \"Treinamento\": f\"T{i+1}\",\n",
    "        \"Vetor de Pesos Inicial\": initial_weights,\n",
    "        \"Vetor de Pesos Final\": final_weights,\n",
    "        \"Número de Épocas\": final_epoch\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row_df], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.67132654 16.02395443 25.45669519 -7.5308065 ]\n",
      "[31.06835909 15.60934439 25.07245809 -7.38660494]\n"
     ]
    }
   ],
   "source": [
    "grouped = results_df.groupby(\"Treinamento\")[\"Vetor de Pesos Final\"].apply(list).reset_index()\n",
    "\n",
    "weights_T1 = np.array(grouped[grouped[\"Treinamento\"] == \"T1\"][\"Vetor de Pesos Final\"].iloc[0])\n",
    "weights_T2 = np.array(grouped[grouped[\"Treinamento\"] == \"T2\"][\"Vetor de Pesos Final\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Após o treinamento do perceptron, aplique-o na classificação automática de novas amostras de óleo (ver arquivo tab_teste1.dat), indicando-se na tabela seguinte os resultados das saídas (Classes) referentes aos dois processos de treinamento realizados no item a.**\n",
    "\n",
    "Para classificar novas amostras usando os pesos finais obtidos após o treinamento vamos criar uma função chamada classify_samples que receberá as novas amostras e os pesos finais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificações usando o treinamento T1: [-1.  1.  1.  1.  1.  1. -1.  1. -1. -1.]\n",
      "Classificações usando o treinamento T2: [-1.  1.  1.  1.  1.  1. -1.  1. -1. -1.]\n",
      "  Amostra      x1      x2      x3  y (T1)  y (T2)\n",
      "0      A1 -0.3565  0.0620  5.9891    -1.0    -1.0\n",
      "1      A2 -0.7842  1.1267  5.5912     1.0     1.0\n",
      "2      A3  0.3012  0.5611  5.8234     1.0     1.0\n",
      "3      A4  0.7757  1.0648  8.0677     1.0     1.0\n",
      "4      A5  0.1570  0.8028  6.3040     1.0     1.0\n",
      "5      A6 -0.7014  1.0316  3.6005     1.0     1.0\n",
      "6      A7  0.3748  0.1536  6.1537    -1.0    -1.0\n",
      "7      A8 -0.6920  0.9404  4.4058     1.0     1.0\n",
      "8      A9 -1.3970  0.7141  4.9263    -1.0    -1.0\n",
      "9     A10 -1.8842 -0.2805  1.2548    -1.0    -1.0\n"
     ]
    }
   ],
   "source": [
    "new_samples = np.loadtxt('tab_teste1.dat')\n",
    "trained_weights = [weights_T1, weights_T2]\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"Amostra\", \"x1\", \"x2\", \"x3\", \"y (T1)\", \"y (T2)\"])\n",
    "\n",
    "# Função para classificar novas amostras\n",
    "def classify_samples(samples, weights):\n",
    "    predictions = np.sign(np.dot(samples, weights[1:]) + weights[0])  # Operação vetorizada\n",
    "    return predictions\n",
    "\n",
    "# Classificar novas amostras para cada treinamento e armazenar no DataFrame\n",
    "all_predictions = []\n",
    "\n",
    "# Classificar novas amostras para cada treinamento\n",
    "for i, weights in enumerate(trained_weights):\n",
    "    predictions = classify_samples(new_samples, weights)\n",
    "    all_predictions.append(predictions)\n",
    "    print(f\"Classificações usando o treinamento T{i+1}: {predictions}\")\n",
    "\n",
    "# Preenchendo o DataFrame\n",
    "for i, sample in enumerate(new_samples):\n",
    "    new_row = {\n",
    "        \"Amostra\": f\"A{i+1}\",\n",
    "        \"x1\": sample[0],\n",
    "        \"x2\": sample[1],\n",
    "        \"x3\": sample[2],\n",
    "        \"y (T1)\": all_predictions[0][i],\n",
    "        \"y (T2)\": all_predictions[1][i],\n",
    "    }\n",
    "    results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# Exibir DataFrame de resultados da classificação\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Explique por que o número de épocas de treinamento varia a cada vez que se executa o treinamento do perceptron.**  \n",
    "\n",
    "Fatores como inicialização de pesos, ordem dos dados, taxa de aprendizado e critérios de convergência contribuem para a variação no número de épocas necessárias para treinar o modelo. No caso específico deste algorítmo, é devido à aleatoriedade dos pesos iniciais.\n",
    "\n",
    "**e. Qual é a principal limitação do perceptron quando aplicado em problemas de classificação de padrões?**  \n",
    "\n",
    "A maior limitação do Perceptron é sua incapacidade de resolver problemas que não são linearmente separáveis. Isso significa que se os dados não podem ser separados por uma única linha reta (em 2D), um plano (em 3D), ou um hiperplano (em mais de três dimensões), o Perceptron não será capaz de encontrar um conjunto de pesos que atinja zero erros no conjunto de treinamento.\n",
    "\n",
    "Esta limitação foi uma das principais razões para o declínio inicial do interesse em redes neurais nos anos 60, especialmente após a publicação do livro \"Perceptrons\" por Marvin Minsky e Seymour Papert, que provou matematicamente essa limitação para o Perceptron de camada única.\n",
    "\n",
    "Para solucionar problemas que não são linearmente separáveis, são necessárias estratégias mais complexas, como a inclusão de camadas ocultas para formar uma rede neural multicamadas (Multilayer Perceptron, MLP) e a aplicação de algoritmos de otimização mais sofisticados, como o backpropagation.\n",
    "\n",
    "Além da limitação de só poder resolver problemas linearmente separáveis, o perceptron também tem outras limitações, como:\n",
    "\n",
    "- Pode ser lento para treinar, especialmente para conjuntos de dados grandes;\n",
    "- Pode ser instável, dependendo da inicialização dos pesos;\n",
    "- Pode ser suscetível a overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Um sistema de gerenciamento automático de controle de duas válvulas, situado a 500 metros de um processo industrial, envia um sinal codificado constituído de quatro grandezas {x1, x2, x3 e x4} que são necessárias para o ajuste de cada uma das válvulas. Conforme mostra a figura abaixo, a mesma via de comunicação é utilizada para acionamento de ambas as válvulas, sendo que o comutador localizado próximo das válvulas deve decidir se o sinal é para a válvula A ou B. Porém, durante a transmissão, os sinais sofrem interferências que alteram o conteúdo das informações transmitidas. Para resolver este problema, treinar-se-á uma rede ADALINE para classificar os sinais ruidosos, que informará ao sistema comutador se os dados devem ser encaminhados para o comando de ajuste da válvula A ou B.**\n",
    "\n",
    "**Assim, baseado nas medições dos sinais já com ruídos, formou-se o conjunto de treinamento no arquivo `tab_treinamento2.dat`, tomando por convenção o valor –1 para os sinais que devem ser encaminhados para o ajuste da válvula A e o valor +1 se os mesmos devem ser enviados para a válvula B.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daí, pede-se:\n",
    "\n",
    "**a. Execute 2 treinamentos para a rede ADALINE inicializando o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos.**  \n",
    "**b. Registre os resultados dos 2 treinamentos acima na tabela abaixo:**  \n",
    "**c. Para os treinamentos realizados, aplique então a rede ADALINE para classificar e informar ao comutador se os sinais seguintes devem ser encaminhados para a válvula A ou B (ver tab_teste2.dat).**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_19692\\2248962648.py:36: RuntimeWarning: overflow encountered in square\n",
      "  cost = (errors**2).sum() / 2.0\n",
      "c:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:49: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:49: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo ada1: 51.43%\n",
      "Acurácia do modelo ada2: 51.43%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>Predição ADA1</th>\n",
       "      <th>Predição ADA2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4329</td>\n",
       "      <td>-1.3719</td>\n",
       "      <td>0.7022</td>\n",
       "      <td>-0.8535</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.2286</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>2.7909</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1349</td>\n",
       "      <td>-0.6445</td>\n",
       "      <td>1.0530</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3374</td>\n",
       "      <td>-1.7163</td>\n",
       "      <td>0.3670</td>\n",
       "      <td>-0.6283</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1434</td>\n",
       "      <td>-0.0485</td>\n",
       "      <td>0.6637</td>\n",
       "      <td>1.2606</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.3749</td>\n",
       "      <td>-0.5071</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>1.3009</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7221</td>\n",
       "      <td>-0.7587</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>-0.5592</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4403</td>\n",
       "      <td>-0.8072</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>-0.3129</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.5231</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>1.5776</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.3255</td>\n",
       "      <td>-2.0000</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>-1.1209</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5824</td>\n",
       "      <td>1.3915</td>\n",
       "      <td>-0.2291</td>\n",
       "      <td>4.1735</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.6081</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>3.2230</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1480</td>\n",
       "      <td>-0.2988</td>\n",
       "      <td>0.4778</td>\n",
       "      <td>0.8649</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.7359</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>-0.0872</td>\n",
       "      <td>2.3584</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.7115</td>\n",
       "      <td>-1.1469</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>0.9573</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.8251</td>\n",
       "      <td>-1.2840</td>\n",
       "      <td>0.8452</td>\n",
       "      <td>1.2382</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1569</td>\n",
       "      <td>0.3712</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>1.7633</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.5389</td>\n",
       "      <td>2.8249</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.4243</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>0.2634</td>\n",
       "      <td>3.5855</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0490</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>1.9792</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.4276</td>\n",
       "      <td>0.5331</td>\n",
       "      <td>-0.0145</td>\n",
       "      <td>3.7286</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.5971</td>\n",
       "      <td>1.4865</td>\n",
       "      <td>0.2904</td>\n",
       "      <td>4.6069</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.8475</td>\n",
       "      <td>2.1479</td>\n",
       "      <td>0.3179</td>\n",
       "      <td>5.8235</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.3967</td>\n",
       "      <td>-0.4171</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>1.3927</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0044</td>\n",
       "      <td>1.5378</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>4.7755</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.2201</td>\n",
       "      <td>-0.5668</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.7829</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.6300</td>\n",
       "      <td>-1.2480</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>0.8093</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.2479</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>1.7381</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.3088</td>\n",
       "      <td>-0.0929</td>\n",
       "      <td>0.8659</td>\n",
       "      <td>1.5483</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.5180</td>\n",
       "      <td>1.4974</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>2.3993</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.6833</td>\n",
       "      <td>0.8266</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>2.8864</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.4353</td>\n",
       "      <td>-1.4066</td>\n",
       "      <td>0.4207</td>\n",
       "      <td>-0.4879</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.1069</td>\n",
       "      <td>-3.2329</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>-2.4572</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.4662</td>\n",
       "      <td>0.6261</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>3.4370</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.8298</td>\n",
       "      <td>-1.4089</td>\n",
       "      <td>0.3119</td>\n",
       "      <td>1.3235</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x1      x2      x3      x4 Predição ADA1 Predição ADA2\n",
       "0   0.4329 -1.3719  0.7022 -0.8535             A             A\n",
       "1   0.3024  0.2286  0.8630  2.7909             A             A\n",
       "2   0.1349 -0.6445  1.0530  0.5687             A             A\n",
       "3   0.3374 -1.7163  0.3670 -0.6283             A             A\n",
       "4   1.1434 -0.0485  0.6637  1.2606             A             A\n",
       "5   1.3749 -0.5071  0.4464  1.3009             A             A\n",
       "6   0.7221 -0.7587  0.7681 -0.5592             A             A\n",
       "7   0.4403 -0.8072  0.5154 -0.3129             A             A\n",
       "8  -0.5231  0.3548  0.2538  1.5776             A             A\n",
       "9   0.3255 -2.0000  0.7112 -1.1209             A             A\n",
       "10  0.5824  1.3915 -0.2291  4.1735             A             A\n",
       "11  0.1340  0.6081  0.4450  3.2230             A             A\n",
       "12  0.1480 -0.2988  0.4778  0.8649             A             A\n",
       "13  0.7359  0.1869 -0.0872  2.3584             A             A\n",
       "14  0.7115 -1.1469  0.3394  0.9573             A             A\n",
       "15  0.8251 -1.2840  0.8452  1.2382             A             A\n",
       "16  0.1569  0.3712  0.8825  1.7633             A             A\n",
       "17  0.0033  0.6835  0.5389  2.8249             A             A\n",
       "18  0.4243  0.8313  0.2634  3.5855             A             A\n",
       "19  1.0490  0.1326  0.9138  1.9792             A             A\n",
       "20  1.4276  0.5331 -0.0145  3.7286             A             A\n",
       "21  0.5971  1.4865  0.2904  4.6069             A             A\n",
       "22  0.8475  2.1479  0.3179  5.8235             A             A\n",
       "23  1.3967 -0.4171  0.6443  1.3927             A             A\n",
       "24  0.0044  1.5378  0.6099  4.7755             A             A\n",
       "25  0.2201 -0.5668  0.0515  0.7829             A             A\n",
       "26  0.6300 -1.2480  0.8591  0.8093             A             A\n",
       "27 -0.2479  0.8960  0.0547  1.7381             A             A\n",
       "28 -0.3088 -0.0929  0.8659  1.5483             A             A\n",
       "29 -0.5180  1.4974  0.5453  2.3993             A             A\n",
       "30  0.6833  0.8266  0.0829  2.8864             A             A\n",
       "31  0.4353 -1.4066  0.4207 -0.4879             A             A\n",
       "32 -0.1069 -3.2329  0.1856 -2.4572             A             A\n",
       "33  0.4662  0.6261  0.7304  3.4370             A             A\n",
       "34  0.8298 -1.4089  0.3119  1.3235             A             A"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **a. Execute 2 treinamentos para a rede ADALINE inicializando o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos.**  \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_sistema = np.loadtxt('tab_treinamento2.dat')\n",
    "\n",
    "df = pd.DataFrame(data_sistema)\n",
    "X = df.iloc[:, 0:4].values  # Entradas\n",
    "y = df.iloc[:, 4].values  # Saídas\n",
    "\n",
    "# Padronização dos dados\n",
    "# Normalização das características de entrada usando o método Z-score\n",
    "mean = X.mean(axis=0)\n",
    "std = X.std(axis=0)\n",
    "X_std = (X - mean) / std\n",
    "\n",
    "# Modelo ADALINE\n",
    "class AdalineGD:\n",
    "    def __init__(self, eta=0.01, epochs=50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, X, y, reinitialize_weights=True):\n",
    "        if reinitialize_weights:\n",
    "            self.w_ = np.random.rand(1 + X.shape[1])\n",
    "            #print(f\"pesos {self.w_}\")\n",
    "            self.initial_weights_ = np.copy(self.w_)\n",
    "        self.cost_ = []\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            output = self.net_input(X)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        return self.net_input(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.where(self.activation(X) >= 0.0, 1, -1)\n",
    "\n",
    "# Treinamento\n",
    "###############\n",
    "eta = 0.1\n",
    "epochs = 6000\n",
    "\n",
    "# Primeiro treinamento\n",
    "ada1 = AdalineGD(eta, epochs)\n",
    "ada1.train(X_std, y)\n",
    "\n",
    "# Segundo treinamento\n",
    "ada2 = AdalineGD(eta, epochs)\n",
    "ada2.train(X_std, y)\n",
    "\n",
    "## Acurácia\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / total\n",
    "\n",
    "# Para modelo ada1\n",
    "predictions_ada1 = ada1.predict(X_std)\n",
    "accuracy_ada1 = accuracy(y, predictions_ada1)\n",
    "\n",
    "# Para modelo ada2\n",
    "predictions_ada2 = ada2.predict(X_std)\n",
    "accuracy_ada2 = accuracy(y, predictions_ada2)\n",
    "\n",
    "print(f\"Acurácia do modelo ada1: {accuracy_ada1 * 100:.2f}%\")\n",
    "print(f\"Acurácia do modelo ada2: {accuracy_ada2 * 100:.2f}%\")\n",
    "\n",
    "# Convergência (Através do Custo)\n",
    "# A convergência do modelo pode ser visualizada examinando a diminuição do custo durante cada época. Se o modelo estiver aprendendo corretamente, o custo deve diminuir à medida que as épocas avançam.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "# Plotando o custo para ada1\n",
    "plt.plot(range(1, len(ada1.cost_) + 1), ada1.cost_, marker='o', label='ADA1')\n",
    "\n",
    "# Plotando o custo para ada2\n",
    "plt.plot(range(1, len(ada2.cost_) + 1), ada2.cost_, marker='x', label='ADA2', linestyle='--')\n",
    "\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Soma dos Erros Quadrados (SE)')\n",
    "plt.legend()\n",
    "plt.title('Convergência da Rede ADALINE')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#**b. Registre os resultados dos 2 treinamentos acima na tabela abaixo:**\n",
    "\n",
    "# Dados para o primeiro treinamento (ada1)\n",
    "initial_weights_ada1 = ada1.initial_weights_\n",
    "final_weights_ada1 = ada1.w_\n",
    "epochs_ada1 = len(ada1.cost_)\n",
    "\n",
    "# Dados para o segundo treinamento (ada2)\n",
    "initial_weights_ada2 = ada2.initial_weights_\n",
    "final_weights_ada2 = ada2.w_\n",
    "epochs_ada2 = len(ada2.cost_)\n",
    "\n",
    "# Inserir os dados no DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"Treinamento\": [\"ADA1\", \"ADA2\"],\n",
    "    \"Vetor de Pesos Inicial\": [initial_weights_ada1, initial_weights_ada2],\n",
    "    \"Vetor de Pesos Final\": [final_weights_ada1, final_weights_ada2],\n",
    "    \"Número de Épocas\": [epochs_ada1, epochs_ada2]\n",
    "})\n",
    "\n",
    "# Separa o vetor inicial em colunas distintas\n",
    "weights_initial_df = results_df['Vetor de Pesos Inicial'].apply(pd.Series)\n",
    "weights_initial_df = weights_initial_df.rename(columns=lambda x: f'Inicial_w{x}')\n",
    "\n",
    "# Separa o vetor final em colunas distintas\n",
    "weights_final_df = results_df['Vetor de Pesos Final'].apply(pd.Series)\n",
    "weights_final_df = weights_final_df.rename(columns=lambda x: f'Final_w{x}')\n",
    "\n",
    "# Concatena com o dataframe original\n",
    "results_df = pd.concat([results_df.drop(columns=['Vetor de Pesos Inicial', 'Vetor de Pesos Final']), weights_initial_df, weights_final_df], axis=1)\n",
    "\n",
    "results_df\n",
    "\n",
    "# **c. Para os treinamentos realizados, aplique então a rede ADALINE para classificar e informar ao comutador se os sinais seguintes devem ser encaminhados para a válvula A ou B (ver tab_teste2.dat).**\n",
    "\n",
    "#data_teste = np.loadtxt('tab_teste2.dat')\n",
    "#X_test = data_teste[:, 0:4]  # sinais de entrada\n",
    "\n",
    "data_teste = np.loadtxt('tab_treinamento2.dat')\n",
    "df_teste = pd.DataFrame(data_sistema)\n",
    "X_test = df_teste.iloc[:, 0:4].values  # Entradas\n",
    "\n",
    "predictions_ada1 = ada1.predict(X_test)\n",
    "#print(f\"Modelo 1 {predictions_ada1}\")\n",
    "predictions_ada2 = ada2.predict(X_test)\n",
    "#print(f\"Modelo 2 {predictions_ada2}\")\n",
    "\n",
    "results_test_df = pd.DataFrame(X_test, columns=[\"x1\", \"x2\", \"x3\", \"x4\"])\n",
    "results_test_df[\"Predição ADA1\"] = predictions_ada1\n",
    "results_test_df[\"Predição ADA2\"] = predictions_ada2\n",
    "\n",
    "# Convertendo os valores para 'A' e 'B' para melhor visualização\n",
    "results_test_df[\"Predição ADA1\"] = results_test_df[\"Predição ADA1\"].apply(lambda x: 'A' if x == -1 else 'B')\n",
    "results_test_df[\"Predição ADA2\"] = results_test_df[\"Predição ADA2\"].apply(lambda x: 'A' if x == -1 else 'B')\n",
    "\n",
    "results_test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
