{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Especialização em Inteligência Artificial – IFMG\n",
    "# Trabalho da disciplina de Redes Neurais e Aprendizado Profundo\n",
    "Autor: Alexandre Fortes Santana\n",
    "\n",
    "Professor: Agnaldo José da Rocha Reis - UFOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. O que é inteligência para você?\n",
    "\n",
    "Para mim, inteligência poderia ser definida pelos tópicos a seguir:\n",
    "- Inteligência se manifesta em diferentes graus e tipos;\n",
    "- Inteligência se desenvolve em um indivíduo, a princípio, biológico;\n",
    "- O indivíduo detentor de inteligência em questão precisa ter a capacidade de memorizar informações em alguma escala;\n",
    "- O indivíduo detentor de inteligência utiliza as informações a que tem acesso para interpretar o mundo a sua volta e a si mesmo;\n",
    "- O indivíduo detentor de inteligência é capaz de decisões, agir e criar novos artefatos (imaginários ou físicos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Em sua opinião, o que aconteceria se alguém descobrisse como implementar uma IA mais abrangente (e.g., AGI) em um robô?\n",
    "A descoberta de uma Inteligência Artificial Geral seria um marco histórico para a humanidade. Experimentaríamos um período de frenesi nas redes sociais, nos noticiários e nas rodas de conversa. Muitos dilemas seriam discutidos, abordando temas como mercado de trabalho, impacto social, segurança, regulação, ética e questões militares. Os primeiros robôs focariam em demonstrar o potencial de suas aplicações e em realizar apresentações que alimentassem o frenesi público. Após um período marcado por medo, especulações e empolgação, veríamos as primeiras aplicações práticas direcionadas a problemas reais. Os primeiros robôs comerciais seriam mais simples, devido ao elevado custo de produção, e não necessariamente seriam humanoides. Não, não acredito que as máquinas se revoltariam, levando a um apocalipse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Análise de um processo de destilação fracionada de petróleo\n",
    "A partir da análise de um processo de destilação fracionada de petróleo observou-se que determinado óleo poderia ser classificado em duas classes de pureza {C1 e C2}, mediante a medição de três grandezas {x1, x2 e x3} que representam algumas das propriedades físico-químicas do óleo. Para tanto, pretende-se utilizar um perceptron para executar a classificação automática dessas duas classes. Assim, baseadas nas informações coletadas do processo, formou-se o conjunto de treinamento em anexo (vou te passar a estrutura de dados nas próximas mensagens), tomando por convenção o valor –1 para óleo pertencente à classe C1 e o valor +1 para óleo pertencente à classe C2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a. Execute dois treinamentos para a rede perceptron, inicializando-se o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergiu na época 433\n",
      "[0.87132654 0.55759443 0.15687519 0.4031135 ]\n",
      "[31.67132654 16.02395443 25.45669519 -7.5308065 ]\n",
      "433\n",
      "Convergiu na época 413\n",
      "[0.46835909 0.13546439 0.47693809 0.48523506]\n",
      "[31.06835909 15.60934439 25.07245809 -7.38660494]\n",
      "413\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Vetor de Pesos Inicial</th>\n",
       "      <th>Vetor de Pesos Final</th>\n",
       "      <th>Número de Épocas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.871327</td>\n",
       "      <td>31.671327</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.557594</td>\n",
       "      <td>16.023954</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.156875</td>\n",
       "      <td>25.456695</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.403114</td>\n",
       "      <td>-7.530806</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.468359</td>\n",
       "      <td>31.068359</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.135464</td>\n",
       "      <td>15.609344</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.476938</td>\n",
       "      <td>25.072458</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.485235</td>\n",
       "      <td>-7.386605</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Treinamento  Vetor de Pesos Inicial  Vetor de Pesos Final Número de Épocas\n",
       "0          T1                0.871327             31.671327              433\n",
       "1          T1                0.557594             16.023954              433\n",
       "2          T1                0.156875             25.456695              433\n",
       "3          T1                0.403114             -7.530806              433\n",
       "4          T2                0.468359             31.068359              413\n",
       "5          T2                0.135464             15.609344              413\n",
       "6          T2                0.476938             25.072458              413\n",
       "7          T2                0.485235             -7.386605              413"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = np.loadtxt('tab_treinamento1.dat')\n",
    "training_data = data[:, :3]\n",
    "labels = data[:, 3]\n",
    "#print(data)\n",
    "#print(training_data)\n",
    "#print(labels)\n",
    "\n",
    "# Bias: Adicionando uma coluna de uns ao conjunto de dados de treinamento\n",
    "training_data = np.c_[np.ones(training_data.shape[0]), training_data]\n",
    "\n",
    "epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Inicialização de pesos\n",
    "def initialize_weights(dim):\n",
    "    return np.random.rand(dim)\n",
    "\n",
    "# Treinamento do Perceptron\n",
    "def train_perceptron(training_data, labels, learning_rate, epochs):\n",
    "    # Inicialização de pesos\n",
    "    weights = initialize_weights(training_data.shape[1])\n",
    "    initial_weights = np.copy(weights)\n",
    "    no_errors = 0\n",
    "    final_epoch = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(training_data)):\n",
    "            x = training_data[i]\n",
    "            y = labels[i]\n",
    "            \n",
    "            # Cálculo do output e função de ativação\n",
    "            output = np.dot(weights, x)\n",
    "            prediction = 1 if output > 0 else -1\n",
    "\n",
    "            #print(\"y:\", y, \"prediction:\", prediction)\n",
    "\n",
    "            # Atualização de pesos\n",
    "            if prediction != y:\n",
    "                weights += learning_rate * (y - prediction) * x\n",
    "                no_errors += 1\n",
    "\n",
    "        if no_errors == 0:\n",
    "            final_epoch = epoch+1\n",
    "            print(f\"Convergiu na época {final_epoch}\")\n",
    "            break\n",
    "        no_errors = 0 # reseta contador de erros\n",
    "                \n",
    "    return initial_weights, weights, final_epoch\n",
    "\n",
    "# DataFrame para armazenar os resultados\n",
    "results_df = pd.DataFrame(columns=[\"Treinamento\", \"Vetor de Pesos Inicial\", \"Vetor de Pesos Final\", \"Número de Épocas\"])\n",
    "\n",
    "# Executando Dois Treinamentos\n",
    "for i in range(2):\n",
    "    initial_weights, final_weights, final_epoch = train_perceptron(training_data, labels, learning_rate, epochs)  \n",
    "    \n",
    "    print(initial_weights)\n",
    "    print(final_weights)\n",
    "    print(final_epoch)\n",
    "\n",
    "    new_row_df = pd.DataFrame({\n",
    "        \"Treinamento\": f\"T{i+1}\",\n",
    "        \"Vetor de Pesos Inicial\": initial_weights,\n",
    "        \"Vetor de Pesos Final\": final_weights,\n",
    "        \"Número de Épocas\": final_epoch\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row_df], ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.67132654 16.02395443 25.45669519 -7.5308065 ]\n",
      "[31.06835909 15.60934439 25.07245809 -7.38660494]\n"
     ]
    }
   ],
   "source": [
    "grouped = results_df.groupby(\"Treinamento\")[\"Vetor de Pesos Final\"].apply(list).reset_index()\n",
    "\n",
    "weights_T1 = np.array(grouped[grouped[\"Treinamento\"] == \"T1\"][\"Vetor de Pesos Final\"].iloc[0])\n",
    "weights_T2 = np.array(grouped[grouped[\"Treinamento\"] == \"T2\"][\"Vetor de Pesos Final\"].iloc[0])\n",
    "#print(weights_T1)\n",
    "#print(weights_T2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Após o treinamento do perceptron, aplique-o na classificação automática de novas amostras de óleo (ver arquivo tab_teste1.dat), indicando-se na tabela seguinte os resultados das saídas (Classes) referentes aos dois processos de treinamento realizados no item a.**\n",
    "\n",
    "Para classificar novas amostras usando os pesos finais obtidos após o treinamento vamos criar uma função chamada classify_samples que receberá as novas amostras e os pesos finais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3565  0.062   5.9891]\n",
      " [-0.7842  1.1267  5.5912]\n",
      " [ 0.3012  0.5611  5.8234]\n",
      " [ 0.7757  1.0648  8.0677]\n",
      " [ 0.157   0.8028  6.304 ]\n",
      " [-0.7014  1.0316  3.6005]\n",
      " [ 0.3748  0.1536  6.1537]\n",
      " [-0.692   0.9404  4.4058]\n",
      " [-1.397   0.7141  4.9263]\n",
      " [-1.8842 -0.2805  1.2548]]\n",
      "[array([31.67132654, 16.02395443, 25.45669519, -7.5308065 ]), array([31.06835909, 15.60934439, 25.07245809, -7.38660494])]\n",
      "Classificações usando o treinamento T1: [-1.  1.  1.  1.  1.  1. -1.  1. -1. -1.]\n",
      "Classificações usando o treinamento T2: [-1.  1.  1.  1.  1.  1. -1.  1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "new_samples = np.loadtxt('tab_teste1.dat')\n",
    "results_df = pd.DataFrame(columns=[\"Amostra\", \"x1\", \"x2\", \"x3\", \"y (T1)\", \"y (T2)\"])\n",
    "\n",
    "# Função para classificar novas amostras\n",
    "def classify_samples(samples, weights):\n",
    "    predictions = np.sign(np.dot(samples, weights[1:]) + weights[0])  # Operação vetorizada\n",
    "    return predictions\n",
    "\n",
    "# Classificar novas amostras para cada treinamento e armazenar no DataFrame\n",
    "all_predictions = []\n",
    "\n",
    "trained_weights = [weights_T1, weights_T2]\n",
    "print(trained_weights)\n",
    "\n",
    "# Classificar novas amostras para cada treinamento\n",
    "for i, weights in enumerate(trained_weights):\n",
    "    predictions = classify_samples(new_samples, weights)\n",
    "    print(f\"Classificações usando o treinamento T{i+1}: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Explique por que o número de épocas de treinamento varia a cada vez que se executa o treinamento do perceptron.**  \n",
    "\n",
    "Fatores como inicialização de pesos, ordem dos dados, taxa de aprendizado e critérios de convergência contribuem para a variação no número de épocas necessárias para treinar o modelo. No caso específico deste algorítmo, é devido à aleatoriedade dos pesos iniciais.\n",
    "\n",
    "**e. Qual é a principal limitação do perceptron quando aplicado em problemas de classificação de padrões?**  \n",
    "\n",
    "A maior limitação do Perceptron é sua incapacidade de resolver problemas que não são linearmente separáveis. Isso significa que se os dados não podem ser separados por uma única linha reta (em 2D), um plano (em 3D), ou um hiperplano (em mais de três dimensões), o Perceptron não será capaz de encontrar um conjunto de pesos que atinja zero erros no conjunto de treinamento.\n",
    "\n",
    "Esta limitação foi uma das principais razões para o declínio inicial do interesse em redes neurais nos anos 60, especialmente após a publicação do livro \"Perceptrons\" por Marvin Minsky e Seymour Papert, que provou matematicamente essa limitação para o Perceptron de camada única.\n",
    "\n",
    "Para solucionar problemas que não são linearmente separáveis, são necessárias estratégias mais complexas, como a inclusão de camadas ocultas para formar uma rede neural multicamadas (Multilayer Perceptron, MLP) e a aplicação de algoritmos de otimização mais sofisticados, como o backpropagation.\n",
    "\n",
    "Além da limitação de só poder resolver problemas linearmente separáveis, o perceptron também tem outras limitações, como:\n",
    "\n",
    "- Pode ser lento para treinar, especialmente para conjuntos de dados grandes;\n",
    "- Pode ser instável, dependendo da inicialização dos pesos;\n",
    "- Pode ser suscetível a overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
